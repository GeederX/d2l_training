{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8fd46ea-a980-43e6-b329-def7ab6f1499",
   "metadata": {},
   "source": [
    "## Dataset download ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683a2ca9-8e19-4757-b9fd-353182ffba97",
   "metadata": {},
   "source": [
    "### Import ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d23a9a45-462b-42f6-bec7-651838a88e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyter_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyter_black\n"
     ]
    }
   ],
   "source": [
    "%load_ext jupyter_black\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import hashlib\n",
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434e655-8c98-42a9-9e4b-b4f59240a744",
   "metadata": {},
   "source": [
    "### Download source config ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f6a795f6-e03f-472d-909e-27db8b0d9f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HUB = dict()\n",
    "DATA_URL = \"http://d2l-data.s3-accelerate.amazonaws.com/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0124a53-4e57-4a55-8206-a83c6536b9fd",
   "metadata": {},
   "source": [
    "### Download ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "13d1e638-c168-4c48-9435-f8e61ec0b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(name, cache_dir=os.path.join(\".\", \"data\")):\n",
    "    assert name in DATA_HUB, f\"{name} is not existed in {DATA_HUB}\"\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split(\"/\")[-1])\n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, \"rb\") as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname\n",
    "    print(f\"Downloading {fname} from {url}\")\n",
    "    r = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd8e845-7c82-4f09-9acc-13c476fbb743",
   "metadata": {},
   "source": [
    "### Add download source ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8af34e03-de6b-4bfc-ba4d-ef7c5736ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HUB[\"kaggle_house_train\"] = (  # @save\n",
    "    DATA_URL + \"kaggle_house_pred_train.csv\",\n",
    "    \"585e9cc93e70b39160e7921475f9bcd7d31219ce\",\n",
    ")\n",
    "\n",
    "DATA_HUB[\"kaggle_house_test\"] = (  # @save\n",
    "    DATA_URL + \"kaggle_house_pred_test.csv\",\n",
    "    \"fa19780a7b011d9b009e8bff8e99922a8ee2eb90\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3127754b-02c0-4b5c-8ee7-496b86e9eae5",
   "metadata": {},
   "source": [
    "## Data Preprocessing ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035e4e92-c935-49ee-9064-e4ad4a0aa94e",
   "metadata": {},
   "source": [
    "### Load dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e0db58b7-c04e-4317-99c5-552747bf9b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(download(\"kaggle_house_train\"))\n",
    "test_data = pd.read_csv(download(\"kaggle_house_test\"))\n",
    "\n",
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a634356-c8fa-4a0f-9638-fca023ab0a1a",
   "metadata": {},
   "source": [
    "### Centering and fill NaN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "954a97e5-5999-4783-8d5a-29846e0bd5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = all_features.dtypes[all_features.dtypes != \"object\"].index\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: ((x - x.mean()) / x.std())\n",
    ")\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff89ce8-9550-4574-9237-34cd0d4fea35",
   "metadata": {},
   "source": [
    "### One hot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c6f69d53-68e8-4692-aa52-76164e7e18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.get_dummies(all_features, dummy_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a901517-c070-4a84-a118-f4aad6c31486",
   "metadata": {},
   "source": [
    "### To Tensor ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cf4d2523-c8de-4021-8788-6bcf71bee540",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = train_data.shape[0]\n",
    "train_features = torch.tensor(\n",
    "    all_features[:n_train].astype(\"float32\").values, dtype=torch.float32\n",
    ")\n",
    "test_features = torch.tensor(\n",
    "    all_features[n_train:].astype(\"float32\").values, dtype=torch.float32\n",
    ")\n",
    "train_labels = torch.tensor(\n",
    "    train_data[\"SalePrice\"].astype(\"float32\").values, dtype=torch.float32\n",
    ").reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da03ae-30b8-443a-96ee-a55c38f27d5b",
   "metadata": {},
   "source": [
    "## Model ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c0a631-9094-4058-a0c9-18b989a431dd",
   "metadata": {},
   "source": [
    "### Hyper params ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e6298116-3460-492f-825c-cb685fcbe387",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = train_features.shape[-1]\n",
    "lr = 0.2\n",
    "wd = 0.5\n",
    "k = 10\n",
    "num_epochs = 200\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db4fc1-14bf-4557-bb78-50b238e03326",
   "metadata": {},
   "source": [
    "### Net Define ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "72a31577-abbf-438c-914a-bb1170ac17b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(num_inputs, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920eeeb2-dd76-48ae-8105-efb39408bdbe",
   "metadata": {},
   "source": [
    "### Function Define ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cb303dc9-d19a-458c-ac3a-b547bcddd9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dc373d",
   "metadata": {},
   "source": [
    "### Iter ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2218e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_iter(data_arrays, batch_size, shuffle):\n",
    "    temp = torch.utils.data.TensorDataset(*data_arrays)\n",
    "    return torch.utils.data.DataLoader(temp, batch_size, shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fe65d6",
   "metadata": {},
   "source": [
    "### Log RMSE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3278f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_rmse(net, features, labels, loss=loss):\n",
    "    temp = torch.clamp(net(features), 1, float(\"inf\"))\n",
    "    loss = torch.sqrt(loss(torch.log(temp), torch.log(labels)))\n",
    "    return float(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23055236-f97f-4ddb-9acc-bf531a6ee67d",
   "metadata": {},
   "source": [
    "### Train ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "046d3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_1_round(\n",
    "    net, train_features, train_labels, test_features, test_labels, optimizer, loss\n",
    "):\n",
    "    train_iter = init_iter(\n",
    "        (train_features, train_labels), batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            l = loss(net(X), y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        test_loss = log_rmse(net, test_features, test_labels)\n",
    "        ###print(f\"      Loss(Log RMSE) in test dataset in {epoch+1}th round is {test_loss}\")\n",
    "    return test_loss\n",
    "\n",
    "\n",
    "def get_k_fold_data(k, i, features, labels):\n",
    "    assert k > 1\n",
    "    lenth = len(features)\n",
    "    assert lenth == len(labels)\n",
    "    fold_size = lenth // k\n",
    "    train_features = torch.cat(\n",
    "        (features[: i * fold_size, :], features[(i + 1) * fold_size :, :]),\n",
    "        dim=0,\n",
    "    )\n",
    "    train_labels = torch.cat(\n",
    "        (labels[: i * fold_size, :], labels[(i + 1) * fold_size :, :]), dim=0\n",
    "    )\n",
    "    test_features = features[i * fold_size : (i + 1) * fold_size, :]\n",
    "    test_labels = labels[i * fold_size : (i + 1) * fold_size, :]\n",
    "    return train_features, train_labels, test_features, test_labels\n",
    "\n",
    "\n",
    "def train(net, features, labels, optimizer, loss, k):\n",
    "    print(f\"Training in {k} folds:\")\n",
    "    for i in range(k):\n",
    "        train_features, train_labels, test_features, test_labels = get_k_fold_data(\n",
    "            k, i, features, labels\n",
    "        )\n",
    "        test_loss = train_1_round(\n",
    "            net,\n",
    "            train_features,\n",
    "            train_labels,\n",
    "            test_features,\n",
    "            test_labels,\n",
    "            optimizer,\n",
    "            loss,\n",
    "        )\n",
    "        print(f\"Loss(Log RMSE) in test dataset in {i+1}st fold is {test_loss}\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63778c4a",
   "metadata": {},
   "source": [
    "## Main ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2da8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in 10 folds:\n",
      "Loss(Log RMSE) in test dataset in 1st fold is 1.5896515846252441\n",
      "Loss(Log RMSE) in test dataset in 2st fold is 0.9664998054504395\n",
      "Loss(Log RMSE) in test dataset in 3st fold is 0.5657472014427185\n",
      "Loss(Log RMSE) in test dataset in 4st fold is 0.35001060366630554\n",
      "Loss(Log RMSE) in test dataset in 5st fold is 0.24345116317272186\n",
      "Loss(Log RMSE) in test dataset in 6st fold is 0.15192225575447083\n",
      "Loss(Log RMSE) in test dataset in 7st fold is 0.15367907285690308\n",
      "Loss(Log RMSE) in test dataset in 8st fold is 0.16232427954673767\n",
      "Loss(Log RMSE) in test dataset in 9st fold is 0.20681971311569214\n",
      "Loss(Log RMSE) in test dataset in 10st fold is 0.15162977576255798\n",
      "Loss in big round1 is 0.15162977576255798\n",
      "Training in 10 folds:\n",
      "Loss(Log RMSE) in test dataset in 1st fold is 0.1620161086320877\n",
      "Loss(Log RMSE) in test dataset in 2st fold is 0.13257470726966858\n",
      "Loss(Log RMSE) in test dataset in 3st fold is 0.15466350317001343\n",
      "Loss(Log RMSE) in test dataset in 4st fold is 0.8909685611724854\n",
      "Loss(Log RMSE) in test dataset in 5st fold is 0.22659006714820862\n",
      "Loss(Log RMSE) in test dataset in 6st fold is 0.12040609121322632\n",
      "Loss(Log RMSE) in test dataset in 7st fold is 0.13233956694602966\n",
      "Loss(Log RMSE) in test dataset in 8st fold is 0.14382056891918182\n",
      "Loss(Log RMSE) in test dataset in 9st fold is 0.1876237988471985\n",
      "Loss(Log RMSE) in test dataset in 10st fold is 0.14482411742210388\n",
      "Loss in big round2 is 0.14482411742210388\n",
      "Training in 10 folds:\n",
      "Loss(Log RMSE) in test dataset in 1st fold is 0.1524803191423416\n",
      "Loss(Log RMSE) in test dataset in 2st fold is 0.12103289365768433\n",
      "Loss(Log RMSE) in test dataset in 3st fold is 0.15583869814872742\n",
      "Loss(Log RMSE) in test dataset in 4st fold is 0.8900582790374756\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[156], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss in big round\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain(net,train_features,train_labels,optimizer,loss,k)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[156], line 3\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss in big round\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain(net,train_features,train_labels,optimizer,loss,k)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[155], line 41\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, features, labels, optimizer, loss, k)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k):\n\u001b[0;32m     38\u001b[0m     train_features, train_labels, test_features, test_labels \u001b[38;5;241m=\u001b[39m get_k_fold_data(\n\u001b[0;32m     39\u001b[0m         k, i, features, labels\n\u001b[0;32m     40\u001b[0m     )\n\u001b[1;32m---> 41\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_1_round\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss(Log RMSE) in test dataset in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mst fold is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m test_loss\n",
      "Cell \u001b[1;32mIn[155], line 8\u001b[0m, in \u001b[0;36mtrain_1_round\u001b[1;34m(net, train_features, train_labels, test_features, test_labels, optimizer, loss)\u001b[0m\n\u001b[0;32m      4\u001b[0m train_iter \u001b[38;5;241m=\u001b[39m init_iter(\n\u001b[0;32m      5\u001b[0m     (train_features, train_labels), batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m train_iter:\n\u001b[0;32m      9\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     10\u001b[0m         l \u001b[38;5;241m=\u001b[39m loss(net(X), y)\n",
      "File \u001b[1;32mc:\\Users\\Geeder\\miniconda3\\envs\\d2l\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:752\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    746\u001b[0m         warn_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    747\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor multiprocessing data-loading, this could be caused by not properly configuring the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    748\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterableDataset replica at each worker. Please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    749\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    750\u001b[0m         )\n\u001b[0;32m    751\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(warn_msg)\n\u001b[1;32m--> 752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Geeder\\miniconda3\\envs\\d2l\\lib\\site-packages\\torch\\autograd\\profiler.py:793\u001b[0m, in \u001b[0;36mrecord_function.__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[0;32m    792\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m--> 793\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_exit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RecordFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    795\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39m_record_function_exit(record)\n",
      "File \u001b[1;32mc:\\Users\\Geeder\\miniconda3\\envs\\d2l\\lib\\site-packages\\torch\\_ops.py:1072\u001b[0m, in \u001b[0;36mTorchBindOpOverload.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1068\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_as_effectful_op_temporarily():\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_in_python(\n\u001b[0;32m   1070\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fallthrough_keys(), \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1071\u001b[0m         )\n\u001b[1;32m-> 1072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    for i in range(5):\n",
    "        print(\n",
    "            f\"Loss in big round{i+1} is {train(net,train_features,train_labels,optimizer,loss,k)}\"\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926b6d23-7858-4787-a83d-4d6d0ef3b362",
   "metadata": {},
   "source": [
    "## Debug ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada062e-7cc8-45d4-8489-0557fa861871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
